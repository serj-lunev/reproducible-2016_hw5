{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "import arff\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_data(X, y):\n",
    "    np.random.seed(42)\n",
    "    inds = np.random.permutation(np.arange(X.shape[0]))\n",
    "    i1, i2 = (np.array([2/8., 3./8]) * X.shape[0]).astype(int)\n",
    "    X_train, y_train = X[inds[:i1]], y[inds[:i1]]\n",
    "    X_val, y_val = X[inds[i1:i2]], y[inds[i1:i2]]\n",
    "    X_test, y_test = X[inds[i2:]], y[inds[i2:]]\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe\n",
    "from hyperopt import hp\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def evaluate_sklearn(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    def create_sklearn_model(params):\n",
    "        return RandomForestClassifier(n_estimators=100, **{k:int(v) for k, v in params.items()})\n",
    "    space = {\n",
    "        'max_depth': hp.qloguniform('max_depth', 0, 6, 1),\n",
    "        'min_samples_split': hp.qloguniform('min_samples_split', 1, 6, 1),\n",
    "        'min_samples_leaf': hp.qloguniform('min_samples_leaf', 0, 6, 1),\n",
    "        'max_leaf_nodes': hp.qloguniform('max_leaf_nodes', 2, 10, 1),\n",
    "    }\n",
    "    best = fmin(lambda params: roc_auc_score(\n",
    "                    y_val,\n",
    "                    create_sklearn_model(params).fit(X_train, y_train).predict_log_proba(X_val)[:,1]),\n",
    "                space, algo=tpe.suggest, max_evals=5)\n",
    "    model = create_sklearn_model(best).fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "    return roc_auc_score(y_test, model.predict_log_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "def evaluate_lgb(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "    space = {\n",
    "        'num_boost_round': hp.qloguniform('num_boost_round', 3, 6, 1),\n",
    "        'num_leaves': hp.qloguniform('num_leaves', 2, 10, 1),\n",
    "        'min_data_in_leaf': hp.qloguniform('min_data_in_leaf', 1, 6, 1),\n",
    "        'max_depth': hp.qloguniform('max_depth', 0, 6, 1),\n",
    "    }\n",
    "\n",
    "    def func(params):\n",
    "        params = {k:int(v) for k, v in params.items()}\n",
    "        num_boost_round = params.pop('num_boost_round')\n",
    "        model = lgb.train(params, train_data, num_boost_round)\n",
    "        return roc_auc_score(y_val, model.predict(X_val))\n",
    "\n",
    "    params = fmin(func, space, algo=tpe.suggest, max_evals=5)\n",
    "    params = {k:int(v) for k, v in params.items()}\n",
    "    num_boost_round = params.pop('num_boost_round')\n",
    "    model = lgb.train({k:int(v) for k, v in params.items()},\n",
    "                      lgb.Dataset(np.concatenate([X_train, X_val]),\n",
    "                                  label=np.concatenate([y_train, y_val])),\n",
    "                      num_boost_round)\n",
    "    return roc_auc_score(y_test, model.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = list(arff.load('/home/serj/Downloads/BayesianNetworkGenerator_tic-tac-toe.arff'))[1:]\n",
    "\n",
    "input_columns = [\n",
    "    'bottom-left-square',\n",
    "    'bottom-middle-square',\n",
    "    'bottom-right-square',\n",
    "    'middle-left-square',\n",
    "    'middle-middle-square',\n",
    "    'middle-right-square',\n",
    "    'top-left-square',\n",
    "    'top-middle-square',\n",
    "    'top-right-square',\n",
    "]\n",
    "target_column = 'Class'\n",
    "\n",
    "input_encoding = {'b': 0, 'x': 1, 'o': 2}\n",
    "target_encoding = {'negative': 0, 'positive': 1}\n",
    "\n",
    "X4 = np.array([[input_encoding[row._data[k]] for k in input_columns]\n",
    "             for row in data])\n",
    "y4 = np.array([target_encoding[row._data[target_column]] for row in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.761789946379\n",
      "0.811586767622\n"
     ]
    }
   ],
   "source": [
    "data_tuple = split_data(X4, y4)\n",
    "print evaluate_sklearn(*data_tuple)\n",
    "print evaluate_lgb(*data_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "с использованием hyperopt (https://github.com/hyperopt/hyperopt/) реализовать сравнение 2 алгоритмов классификации\n",
    "\n",
    "    sklearn.ensemble.RandomForestClassifier https://github.com/scikit-learn/scikit-learn/blob/8d072fb/sklearn/ensemble/forest.py#L744\n",
    "    LightGBM (https://github.com/Microsoft/LightGBM)\n",
    "\n",
    "датасеты:\n",
    "\n",
    "    https://www.openml.org/d/1216\n",
    "    https://www.openml.org/d/1241\n",
    "    https://www.openml.org/d/4154\n",
    "    https://www.openml.org/d/137\n",
    "    https://www.openml.org/d/1178\n",
    "\n",
    "(можно на свое усмотрение выбрать другие алгоритмы и датасеты)\n",
    "\n",
    "схема сравнения:\n",
    "\n",
    "    делим датасет на 3 части X_train, X_val, X_test в пропорциях 2:1:5\n",
    "    подбираем оптимальные параметры классификатора на X_train, выбираем такой набор, который дает лучшее качество на X_val (используем hyperopt)\n",
    "    с этим набором параметров обучаем на X_train + X_val и применяем к X_test - качество (ROC_AUC сохраняем в табличку)\n",
    "    повторяем для всех датасетов и всех классификаторов\n",
    "    в конце упражнения для каждого классификатора получаем набор значений ROC_AUC (5 штук), который рисуем на графике - а-ля (https://github.com/openml/study_example/blob/master/StudyTest.ipynb)\n",
    "    весь код + тетрадки сохранить в виде репозитория на github, который запускается с помощью everware\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
